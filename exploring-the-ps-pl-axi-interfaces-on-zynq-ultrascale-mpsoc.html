<!DOCTYPE html>
<html lang="en">
<head>
        <title>Exploring the PS-PL AXI interfaces on Zynq UltraScale+ MPSoC</title>
        <meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <link rel="shortcut icon" href="./theme/images/favicon.ico"/>
        <link rel="stylesheet" href="./theme/css/main.css" type="text/css" />
        <link href="www.j-marjanovic.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="j-marjanovic.io Atom Feed" />
</head>

<body id="index" class="home">

	
  <!-- <header id="banner" class="body"> -->
  <!--               <h1><a href="./"><img src="http://www.launchyard.com/images/logo.png" /></a></h1> -->
  <!--       </header> --> 

  <div class="LaunchyardDetail" style="align:right;">
    <!-- <p> -->
    <!-- <img src="./theme/images/blue-pin.png" width="100" height="100" alt="Graph icon"> -->
    <!-- </p> -->
    <p><a id="sitesubtitle" href="./">j-marjanovic.io</a></p>

	<br>
    <p style="float: right; margin-right: 50px;"><a id="aboutlink" href="./pages/about.html">About</a></p>
    <br>

    <p style="float: right; margin-right: 50px;"><a id="cv" href="./cv/resume_jan_marjanovic_2022.pdf" target="_blank">CV</a></p>
    <br>

    <p style="float: right; margin-right: 50px;"><img src="./theme/images/icons/rss.png"> <a id="aboutlink" href="./feeds/jan-marjanovic.atom.xml">Atom feed</a></p>
    <br>

  </div>

<section id="content" >
    <div class="body">
      <article>
        <header>
          <h1 class="entry-title">
            <a href="./exploring-the-ps-pl-axi-interfaces-on-zynq-ultrascale-mpsoc.html" rel="bookmark"
               title="Permalink to Exploring the PS-PL AXI interfaces on Zynq UltraScale+ MPSoC">Exploring the PS-PL AXI interfaces on Zynq UltraScale+ MPSoC</a></h1>

        </header>

        <div class="entry-content">
<div class="post-info">
	<ul>
        <li class="vcard author">
                 by&nbsp;<a class="url fn" href="./author/jan-marjanovic.html">Jan Marjanovic</a>
        </li>
        <li class="published" title="2021-12-29T18:00:00+01:00">
          on&nbsp;Wed 29 December 2021
        </li>

	</ul>

</div><!-- /.post-info -->          <p>I recently held <a href="https://indico.desy.de/event/31387/contributions/112660/">a presentation at the 10th MicroTCA Workshop for Industry and
Research</a>, where I
presented some hardware we have developed, discussed the advantages of using
SoCs, and showed a couple of examples where we successfully leveraged the features
of these devices.</p>
<p>At my day job the dataflow through the system is relatively simple, the data
is captured in large chunks and the direction is always well defined, i.e.
for data acquisition systems from FPGA to CPU and then into the network/storage.</p>
<p>On the other hand, there are a lot of applications that can benefit from a
tighter coupling between the CPU and the FPGA, for example: HW-accelerated
compression and decompression, HW-accelerated regex, HW-accelerated graph
traversal, machine learning accelerators,...</p>
<p>This is why I have decided to explore all ports available in Zynq US+ MPSoC in
my free time and to describe this adventure in this blog post.</p>
<h1>Introduction</h1>
<p>Xilinx Zynq UltraScale+ MPSoC provides four different types of interfaces
between the so-called <em>Processing System (PS)</em> and <em>Programmable Logic (PL)</em>,
leveraging the wide variety of different protocols standardized in <a href="https://developer.arm.com/architectures/system-architectures/amba">Advanced
Microcontroller Bus
Architecture</a>.</p>
<p>In this blog post I will explore the performance characteristics of three
different interfaces:  </p>
<ul>
<li>Accelerator Coherency Port interface</li>
<li>High-Performance Coherent interface</li>
<li>High-Performance interface</li>
</ul>
<p><em>AXI Coherency Extension</em> port is the most interesting of all and it deserves
a dedicated blog post.</p>
<p>The purpose of this blog post is to gather information on how to make the
interfaces work correctly and to measure the performance in different scenarios.
The information on various interfaces is scattered across different documents
(<a href="https://www.xilinx.com/support/documentation/user_guides/ug1085-zynq-ultrascale-trm.pdf">Zynq UltraScale+ Device Technical Reference
Manual</a>,
<a href="https://developer.arm.com/documentation/ddi0470/">CoreLink CCI-400 Cache Coherent Interconnect Technical Reference
Manual</a>, and <a href="https://developer.arm.com/documentation/ddi0500/">Arm Cortex-A53
MPCore Processor Technical Reference
Manual</a>), <a href="https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/18842098/Zynq+UltraScale+MPSoC+Cache+Coherency">Xilinx wiki
pages</a>,
<a href="https://www.xilinx.com/support/answers/69446.html">Xilinx Answer Records</a> and
various forum threads and GitHub issues.</p>
<h2>PL-PS Interfaces</h2>
<p>Shown in the figure below are the interfaces between PS and PL.</p>
<p><img alt="PS-PL AXI Interface Datapaths - from UG1085 (courtesy Xilinx)" src="./images/2021_zynqmp_ports/intro/ug1085_ps_pl_axi_interface.png" style="width:40%; display: block; margin-left: auto; margin-right: auto;"></p>
<p>In this blog post I will focus on the following three interfaces:</p>
<h3>High-Performance interface</h3>
<p>This interface connects directly to the <em>DDR Memory Subsystem</em> and completely
bypasses the Cache Coherent Interconnect and the APU. According to UG1085, this
interface is ideal for large datasets. The software needs to bypass the
cache when accessing the data.</p>
<h3>High-Performance Coherent interface</h3>
<p>This interface is connected to a port on CCI-400 interconnect. When configured
accordingly the memory transactions are communicated to the APU, providing
tighter integration with software.</p>
<p>AR 69446 mentions that:</p>
<blockquote>
<p>The HPC ports are preferable to the ACP port in most applications as they
provide higher bandwidth and do not disturb the contents of the processor L2
cache.</p>
</blockquote>
<h3>Accelerator Coherency Port interface</h3>
<p>Cortex-A53 TRM describes the ACP interface in the following way:</p>
<blockquote>
<p>The ACP is provided to reduce software cache maintenance operations when
sharing memory regions with other masters, and to allow other masters to
allocate data into the L2 cache.</p>
</blockquote>
<p>According to UG1085:</p>
<blockquote>
<p>[...] ACP is optimal for medium-grain acceleration, such as a
block-level crypto accelerator and video macro-block level processing.</p>
</blockquote>
<h1>Motivation</h1>
<p>Cache-aware interfaces allow tighter integration between SW and HW which is of
particular interest for accelerating workloads with FPGA. Instead of explicitly
copying the data to the FPGA, doing the computation in the FPGA, and copying
data back from the FPGA, with cache-aware interfaces we can modify the data
directly in the program memory, thus skipping the unnecessary copying.</p>
<p>I have prepared <a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces/blob/rel-v2021.1/recipes-app/numpy-acc/files/numpy_example.ipynb">a Jupyter
notebook</a>
that demonstrates this approach. An AXI Proxy (explained in detail in the
next chapter)  is used to read from and to a Numpy array.</p>
<p>The screenshot below shows the most important part of the notebook, where the
AXI Proxy is used to modify the content of the Numpy array from the FPGA side.</p>
<p><img alt="Writing to a Numpy array" src="./images/2021_zynqmp_ports/motivation/numpy_acc.png" style="width:60%; display: block; margin-left: auto; margin-right: auto;"></p>
<h1>Test setup</h1>
<h2>Hardware</h2>
<p>All measurements were performed on an Ultra96-V2 board. The board contains an
XCZU3EG, 2GB of DDR4 memory connected to the Processing System, and not much
more.</p>
<p>The blue LED near the USB connector is used to indicate activity on AXI PL-PS ports:</p>
<p><img alt="Ultra96-V2" src="./images/2021_zynqmp_ports/intro/u96.jpg" style="width:50%; display: block; margin-left: auto; margin-right: auto;"></p>
<h2>AXI Proxy</h2>
<p><a href="https://github.com/j-marjanovic/chisel-stuff/tree/master/example-12-axi-proxy">AXI Proxy
IP</a>
acts (as the name suggests) as a proxy between an AXI4-Lite subordinate port and
an AXI4 manager port. With this IP we can measure read and write latency on
all aforementioned ports.</p>
<p>The subordinate port provides registers where the software can prepare the data
to be written, retrieve the data which was read, start read and write
transactions and measure the time an individual transaction took. The
transaction time is measured in clock cycles between an address being provided
(<code>AxVALID</code> going high) and a full response is received. To match the
requirements of the ACP interface, all transactions are 64-byte long (4 beats,
128-bit wide). The software has also the possibility to set some of the <a href="https://github.com/j-marjanovic/chisel-stuff/blob/master/example-12-axi-proxy/src/main/scala/axi_proxy/AxiProxy.scala#L136">AXI
side-band
signals</a>
which affect the caching properties: <code>AxCACHE</code>, <code>AxPROT</code>, and <code>AxUSER</code>.</p>
<p>Shown in the figure below is the Vivado block diagram used to perform the tests
with <strong>AXI Proxy</strong>. There are three instances of the IP, each connected to one
of the ports on the Zynq MPSoC block. System ILA is used to provide additional
visibility of the connections between AXI Proxy and PL-PS ports on the Zynq
UltraScale+ MPSoC block.</p>
<p><img alt="AXI Proxy" src="./images/2021_zynqmp_ports/intro/vivado_axi_proxy.png" style="width:60%; display: block; margin-left: auto; margin-right: auto;"></p>
<h2>AXI Traffic Generator</h2>
<p><a href="https://github.com/j-marjanovic/chisel-stuff/tree/master/example-13-axi-traffic-gen">AXI Traffic
Generator</a>
can generate a sequence of AXI bursts with an incrementing address and a known
pattern, which simulates behavior of a DMA. With this IP we can measure the read
and write throughput of transactions of different sizes.</p>
<p>Also here each AXI burst contains 64 bytes (4 beats, 128-bit). The IP measures
the number of clock cycles the entire transfer took.</p>
<p>Shown in the figure below is the Vivado block diagram used to perform the tests
with <strong>Jan's AXI Traffic Generator</strong>. As with the AXI Proxy, there are three
instances and a System ILA to observe the transactions.</p>
<p><img alt="AXI Traffic Generator" src="./images/2021_zynqmp_ports/intro/vivado_axi_tg.png" style="width:60%; display: block; margin-left: auto; margin-right: auto;"></p>
<h2>Yocto layer</h2>
<p>To generate the SD card image containing:</p>
<ul>
<li>the FPGA bitstreams, </li>
<li>FPGA manager (to download the bitstreams), </li>
<li>device tree overlays (the description of FPGA),</li>
<li>programs to control the IPs, </li>
<li>the required Python libraries and </li>
<li>Jupyter notebooks</li>
</ul>
<p>I have created a Yocto layer, available on my GitHub:
<a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces">meta-zynqmp-pl-ps-interfaces</a>.
The usage description is available in the <code>README.md</code>.</p>
<h2>Configuration</h2>
<h3>u-dma-buf</h3>
<p>For use with ACP and HPC port, the u-dma-buffer needs to have the
<a href="https://github.com/ikwzm/udmabuf#dma-coherent"><code>dma-coherent</code></a> flag set.
This is achieved with <a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces/blob/rel-v2021.1/recipes-bsp/device-tree/files/app-pl-custom.dtsi#L6-L12">an entry</a> in the device tree.</p>
<h3>HP port</h3>
<p>HP port requires no special configuration on the FPGA side, and the <code>u-dma-buf</code>
needs to be opened with the <a href="https://github.com/ikwzm/udmabuf#when-hardware-does-not-maintain-the-coherency"><code>O_SYNC</code> flag</a>.</p>
<h3>HPC port</h3>
<h4>Addressing</h4>
<p>The HPC by default uses physical addressing, although the SMMU can be configured
to use the virtual addressing, as mentioned in UG1085:</p>
<blockquote>
<p>"Comparably, S_AXI_HPCx_FPD uses a virtual address [...]"</p>
</blockquote>
<h4>FSBL and reg.init</h4>
<p><a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces/tree/rel-v2021.1/recipes-bsp/fsbl/files">A couple of
patches</a>
for the FSBL configure CCI in the correct configuration so that the
transactions on the HPC port are considered shareable.</p>
<h3>ACP port</h3>
<p>The ACP interface is in detail described in <a href="https://developer.arm.com/documentation/ddi0500/e/level-2-memory-system/acp">ARM Cortex-A53 MPCore Processor
Technical Reference
Manual</a>.</p>
<p>Since this interface provides direct access into L2 cache, and therefore the
transfer needs to follow certain restrictions: to achieve the best performance
the transfers should be 64 bytes long (one cache line), and <code>AxCACHE</code> and
<code>AxPROT</code> signals need to be set to certain values.</p>
<ul>
<li><a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/Transaction-Attributes/Memory-types">Memory types</a></li>
<li><a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/Transaction-Attributes/Access-permissions">Access permissions</a></li>
<li><a href="https://developer.arm.com/documentation/ddi0500/e/level-2-memory-system/acp/acp-user-signals">ACP user signals</a></li>
</ul>
<h4>regs.init</h4>
<p><a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces/blob/rel-v2021.1/recipes-bsp/bootbin/files/regs.init">regs.init</a> is used to write to the APU Configuration Register (<code>LPD_SLCR</code>), which
enables the broadcasting of the transactions towards the CCI, as described on
<a href="https://xilinx-wiki.atlassian.net/wiki/spaces/A/pages/18842098/Zynq+UltraScale+MPSoC+Cache+Coherency#ZynqUltraScaleMPSoCCacheCoherency-5.2.2RegisterWriteAtEarlyBoot">Xilinx Wiki on Cache
Coherence</a>.</p>
<h1>Measurements</h1>
<h2>Throughput/interface utilization</h2>
<p>The throughput was measured with the AXI Traffic Generator, described in one of the
previous chapters. What we measure here is not strictly throughput but
interface utilization, i.e. in what percentage of the clock cycles was there a
beat transmitted on the port. One can easily derive the throughput (in B/s) from
the interface parameters (16-byte wide, running at 250 MHz). During the tests,
only one interface was active at the time.</p>
<ul>
<li>The entire measurement procedure is documented in a Jupyter notebook: <a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces/blob/rel-v2021.1/recipes-app/apps-pl-ps-interfaces/files/notebooks/00-traffic-gen.ipynb">00-traffic-gen.ipynb</a></li>
<li>The FPGA project for Ultra96-V2 board is available here: <a href="https://github.com/j-marjanovic/chisel-stuff/tree/master/example-13-axi-traffic-gen/ultra96v2_prj">example-13-axi-traffic-gen/ultra96v2_prj</a></li>
</ul>
<p>The final results are presented in the graph below.</p>
<p><img alt="Interface utilization measurement" src="./images/2021_zynqmp_ports/meas/throughput_250MHz.png" style="width:60%; display: block; margin-left: auto; margin-right: auto;"></p>
<p>The HP port exhibits a typical behavior of a process where the start-up time
plays a significant role - the interface utilization is lower for smaller
transactions, but approaches an asymptotical limit at a certain size. All ports
use the same settings (4 transactions in flight, 64 bytes per transaction) to
make the comparison between different ports fair; this value is clearly too
low for the long latencies of DDR4. To achieve higher throughput, one should
increase the burst length.</p>
<p>CCI adds additional latency to the HPC port and the throughput on this port is
even lower. Interestingly, once the transfer size is larger than the L2 cache,
the interface utilization starts getting higher. This would indicate that the
cache switches to write-through "mode" once it has seen a certain access
pattern; the CCI400 TRM is quite vague in this regard.</p>
<p>The ACP benefits from the L1 and L2 caches and the interface utilization is the
highest of all ports for small transfers (below 1 MB). Once the transfer size
gets larger than the L2 cache size the interface utilization is severely
affected.</p>
<h2>Latency</h2>
<p>The latency was measured with AXI Proxies. A single measurement sample was
obtained with the following procedure:</p>
<ol>
<li>the SW generates a random value and instructs AXI Proxy to write this random
   value into a shared buffer through one of the ports</li>
<li>the SW then reads the data from the buffer and compares it to what AXI
   Proxy has written</li>
<li>the SW then generates another random value and writes it directly to the
   buffer</li>
<li>the SW then instructs the AXI Proxy to read the data and then compares the
   value to the previously generated value</li>
</ol>
<p>With this procedure we can check that the writes and reads are visible in both
directions, and this procedure also mimics a typical usage of an FPGA
accelerator. During the tests, only one interface was active at the time.</p>
<ul>
<li>The entire measurement procedure is documented in a Jupyter notebook: <a href="https://github.com/j-marjanovic/meta-zynqmp-pl-ps-interfaces/blob/rel-v2021.1/recipes-app/apps-pl-ps-interfaces/files/notebooks/02-axi-proxy-on-repeat.ipynb">02-axi-proxy-on-repeat.ipynb</a></li>
<li>The FPGA project for Ultra96 board is available here: <a href="https://github.com/j-marjanovic/chisel-stuff/tree/master/example-12-axi-proxy/ultra96v2_prj">example-12-axi-proxy/ultra96v2_prj</a></li>
</ul>
<p>The results of the latency measurements are presented in the graph below.</p>
<p><img alt="Latency measurement" src="./images/2021_zynqmp_ports/meas/latency_250MHz.png" style="width:60%; display: block; margin-left: auto; margin-right: auto;"></p>
<p>On the cached interfaces (ACP and HPC) we see, expectedly, very uniform latency
values. On the other side, on the HP interface we see that the latency to the
DDR4 is quite high and also quite variable, presumably because the transaction
needs to be scheduled after some other transactions or memory refresh is
currently being performed.</p>
<p>There is an interesting start-up behavior on the ACP and HPC interfaces. I am
assuming that the L2 cache is an <em>inclusive cache</em> and contains all lines from
the L1 cache. When a write request arrives at the L2 cache and the line is in
<em>Invalid</em> state, the L2 can immediately decide that it can acknowledge the write
transaction. When the write request arrives at the L1 cache, however, the L1
cache needs to first inform the L2 cache to invalidate the line, and only then
proceed by acknowledging the write transaction.</p>
<h1>Conclusion</h1>
<p>In this blog post I have explored three different types of interfaces between PL
and PS in Zynq UltraScale+ MPSoC. Different types of interfaces provide
different trade-offs in terms of coupling between SW/HW, ease of use,
throughput, and latency. Cache-aware interfaces can be used to access the data
structures in running software and can therefore be used to seamlessly
accelerate certain parts of the program.</p>
<p>Some edge cases were not explored (e.g. increasing the burst length for the
interface utilization measurement), but I decided to skip those to make the blog
post short(er). With Zynq US+ MPSoC boards being ubiquitous, this task is "left
as an exercise to the reader".</p>
<p>I hope that this blog post, alongside the Vivado projects and the Yocto layer
can be used as a reference on how to use those ports.</p>
<hr>
<h1>Appendix</h1>
<h2>System ILA waveforms</h2>
<h3>AXI Proxy</h3>
<h4>HP port</h4>
<div class="highlight"><pre><span></span><code><span class="gp">root@u96v2-sbc:~# </span>app-axi-proxy --interface hp --use-osync
<span class="go">Udmabuf</span>
<span class="go">  name = axi:udmabuf@0x0</span>
<span class="go">  virt addr = 0xffff9c0c7000</span>
<span class="go">  phys addr = 0x5e100000</span>
<span class="go">  size = 33554432</span>
<span class="go">  flags = 0x101002</span>
<span class="go">UioDevice{number =  5, name =             AxiProxy, addr = 0xa0020000, size = 65536, note = hp}</span>
<span class="go">UioDevice{number =  6, name =             AxiProxy, addr = 0xa0030000, size = 65536, note = hpc}</span>
<span class="go">UioDevice{number =  4, name =             AxiProxy, addr = 0xa0040000, size = 65536, note = acp}</span>
<span class="go">UioDevice{number =  1, name =             axi-pmon, addr = 0xfd0b0000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  2, name =             axi-pmon, addr = 0xfd490000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  0, name =             axi-pmon, addr = 0xffa00000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  3, name =             axi-pmon, addr = 0xffa10000, size = 65536, note = }</span>
<span class="go">AxiProxy info:</span>
<span class="go">  id reg = 0xa8122081</span>
<span class="go">  version = 0.3.1</span>
<span class="go">SW read, HW written:</span>
<span class="go">  10, 10</span>
<span class="go">  20, 20</span>
<span class="go">  30, 30</span>
<span class="go">  40, 40</span>
<span class="go">readback, expected:</span>
<span class="go">  10, 10</span>
<span class="go">  20, 20</span>
<span class="go">  30, 30</span>
<span class="go">  40, 40</span>
<span class="go">stats: dur_wr = 36, dur_rd = 70</span>
</code></pre></div>

<p><img alt="AXI Proxy read and write - HP port" src="./images/2021_zynqmp_ports/system_ila/proxy_hp.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<h4>HPC port</h4>
<div class="highlight"><pre><span></span><code><span class="gp">root@u96v2-sbc:~# </span>app-axi-proxy --interface hpc --axi-cache <span class="m">15</span> --axi-prot <span class="m">2</span> --axi-user <span class="m">1</span>
<span class="go">Udmabuf</span>
<span class="go">  name = axi:udmabuf@0x0</span>
<span class="go">  virt addr = 0xffff931d8000</span>
<span class="go">  phys addr = 0x5e100000</span>
<span class="go">  size = 33554432</span>
<span class="go">  flags = 0x2</span>
<span class="go">UioDevice{number =  5, name =             AxiProxy, addr = 0xa0020000, size = 65536, note = hp}</span>
<span class="go">UioDevice{number =  6, name =             AxiProxy, addr = 0xa0030000, size = 65536, note = hpc}</span>
<span class="go">UioDevice{number =  4, name =             AxiProxy, addr = 0xa0040000, size = 65536, note = acp}</span>
<span class="go">UioDevice{number =  1, name =             axi-pmon, addr = 0xfd0b0000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  2, name =             axi-pmon, addr = 0xfd490000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  0, name =             axi-pmon, addr = 0xffa00000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  3, name =             axi-pmon, addr = 0xffa10000, size = 65536, note = }</span>
<span class="go">AxiProxy info:</span>
<span class="go">  id reg = 0xa8122081</span>
<span class="go">  version = 0.3.1</span>
<span class="go">SW read, HW written:</span>
<span class="go">  10, 10</span>
<span class="go">  20, 20</span>
<span class="go">  30, 30</span>
<span class="go">  40, 40</span>
<span class="go">readback, expected:</span>
<span class="go">  10, 10</span>
<span class="go">  20, 20</span>
<span class="go">  30, 30</span>
<span class="go">  40, 40</span>
<span class="go">stats: dur_wr = 46, dur_rd = 40</span>
</code></pre></div>

<p><img alt="AXI Proxy read and write - HPC port" src="./images/2021_zynqmp_ports/system_ila/proxy_hpc.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<h4>ACP port</h4>
<div class="highlight"><pre><span></span><code><span class="gp">root@u96v2-sbc:~# </span>app-axi-proxy --interface acp --axi-cache <span class="m">15</span> --axi-prot <span class="m">2</span> --axi-user <span class="m">1</span>
<span class="go">Udmabuf</span>
<span class="go">  name = axi:udmabuf@0x0</span>
<span class="go">  virt addr = 0xffffa1356000</span>
<span class="go">  phys addr = 0x5e100000</span>
<span class="go">  size = 33554432</span>
<span class="go">  flags = 0x2</span>
<span class="go">UioDevice{number =  5, name =             AxiProxy, addr = 0xa0020000, size = 65536, note = hp}</span>
<span class="go">UioDevice{number =  6, name =             AxiProxy, addr = 0xa0030000, size = 65536, note = hpc}</span>
<span class="go">UioDevice{number =  4, name =             AxiProxy, addr = 0xa0040000, size = 65536, note = acp}</span>
<span class="go">UioDevice{number =  1, name =             axi-pmon, addr = 0xfd0b0000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  2, name =             axi-pmon, addr = 0xfd490000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  0, name =             axi-pmon, addr = 0xffa00000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  3, name =             axi-pmon, addr = 0xffa10000, size = 65536, note = }</span>
<span class="go">AxiProxy info:</span>
<span class="go">  id reg = 0xa8122081</span>
<span class="go">  version = 0.3.1</span>
<span class="go">SW read, HW written:</span>
<span class="go">  10, 10</span>
<span class="go">  20, 20</span>
<span class="go">  30, 30</span>
<span class="go">  40, 40</span>
<span class="go">readback, expected:</span>
<span class="go">  10, 10</span>
<span class="go">  20, 20</span>
<span class="go">  30, 30</span>
<span class="go">  40, 40</span>
<span class="go">stats: dur_wr = 25, dur_rd = 14</span>
</code></pre></div>

<p><img alt="AXI Proxy read and write - ACP port" src="./images/2021_zynqmp_ports/system_ila/proxy_acp.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<h3></h3>
<h4>HP port</h4>
<div class="highlight"><pre><span></span><code><span class="gp">root@u96v2-sbc:~# </span>app-axi-traffic-gen --count <span class="m">32</span> --interface hp --use-osync
<span class="go">UioDevice{number =  4, name =        AxiTrafficGen, addr = 0xa0040000, size = 65536, note = acp}</span>
<span class="go">UioDevice{number =  5, name =        AxiTrafficGen, addr = 0xa0050000, size = 65536, note = hp}</span>
<span class="go">UioDevice{number =  6, name =        AxiTrafficGen, addr = 0xa0060000, size = 65536, note = hpc}</span>
<span class="go">UioDevice{number =  1, name =             axi-pmon, addr = 0xfd0b0000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  2, name =             axi-pmon, addr = 0xfd490000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  0, name =             axi-pmon, addr = 0xffa00000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  3, name =             axi-pmon, addr = 0xffa10000, size = 65536, note = }</span>
<span class="go">AxiTrafficGen info:</span>
<span class="go">  id reg = 0xa8172a9e</span>
<span class="go">  version = 0.9.7</span>
<span class="go">Udmabuf</span>
<span class="go">  name = axi:udmabuf@0x0</span>
<span class="go">  virt addr = 0xffff954fe000</span>
<span class="go">  phys addr = 0x5e100000</span>
<span class="go">  size = 33554432</span>
<span class="go">  flags = 0x101002</span>
<span class="go">Transfering 32 bursts</span>
<span class="go">Memory check (size = 32 bursts) successfully completed</span>
<span class="go">Memory check (size = 32 bursts) successfully completed</span>
<span class="go">stats: rd cyc = 670, wr cyc = 265, rd_ok = 128</span>
</code></pre></div>

<p><img alt="AXI Traffic Generator write and read - HP port" src="./images/2021_zynqmp_ports/system_ila/tg_hp.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<h4>HPC port</h4>
<div class="highlight"><pre><span></span><code><span class="gp">root@u96v2-sbc:~# </span>app-axi-traffic-gen --count <span class="m">32</span> --interface hpc --axi-cache <span class="m">15</span> --axi-prot <span class="m">2</span> --axi-user <span class="m">1</span>
<span class="go">UioDevice{number =  4, name =        AxiTrafficGen, addr = 0xa0040000, size = 65536, note = acp}</span>
<span class="go">UioDevice{number =  5, name =        AxiTrafficGen, addr = 0xa0050000, size = 65536, note = hp}</span>
<span class="go">UioDevice{number =  6, name =        AxiTrafficGen, addr = 0xa0060000, size = 65536, note = hpc}</span>
<span class="go">UioDevice{number =  1, name =             axi-pmon, addr = 0xfd0b0000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  2, name =             axi-pmon, addr = 0xfd490000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  0, name =             axi-pmon, addr = 0xffa00000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  3, name =             axi-pmon, addr = 0xffa10000, size = 65536, note = }</span>
<span class="go">AxiTrafficGen info:</span>
<span class="go">  id reg = 0xa8172a9e</span>
<span class="go">  version = 0.9.7</span>
<span class="go">Udmabuf</span>
<span class="go">  name = axi:udmabuf@0x0</span>
<span class="go">  virt addr = 0xffffa781e000</span>
<span class="go">  phys addr = 0x5e100000</span>
<span class="go">  size = 33554432</span>
<span class="go">  flags = 0x2</span>
<span class="go">Transfering 32 bursts</span>
<span class="go">Memory check (size = 32 bursts) successfully completed</span>
<span class="go">Memory check (size = 32 bursts) successfully completed</span>
<span class="go">stats: rd cyc = 391, wr cyc = 756, rd_ok = 128</span>
</code></pre></div>

<p><img alt="AXI Traffic Generator write - HPC port" src="./images/2021_zynqmp_ports/system_ila/tg_hpc_write.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<p><img alt="AXI Traffic Generator reads - HPC port" src="./images/2021_zynqmp_ports/system_ila/tg_hpc_read.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<h4>ACP port</h4>
<div class="highlight"><pre><span></span><code><span class="gp">root@u96v2-sbc:~# </span>app-axi-traffic-gen --count <span class="m">32</span> --interface acp --axi-cache <span class="m">15</span> --axi-prot <span class="m">2</span> --axi-user <span class="m">1</span>     
<span class="go">UioDevice{number =  4, name =        AxiTrafficGen, addr = 0xa0040000, size = 65536, note = acp}</span>
<span class="go">UioDevice{number =  5, name =        AxiTrafficGen, addr = 0xa0050000, size = 65536, note = hp}</span>
<span class="go">UioDevice{number =  6, name =        AxiTrafficGen, addr = 0xa0060000, size = 65536, note = hpc}</span>
<span class="go">UioDevice{number =  1, name =             axi-pmon, addr = 0xfd0b0000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  2, name =             axi-pmon, addr = 0xfd490000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  0, name =             axi-pmon, addr = 0xffa00000, size = 65536, note = }</span>
<span class="go">UioDevice{number =  3, name =             axi-pmon, addr = 0xffa10000, size = 65536, note = }</span>
<span class="go">AxiTrafficGen info:</span>
<span class="go">  id reg = 0xa8172a9e</span>
<span class="go">  version = 0.9.7</span>
<span class="go">Udmabuf</span>
<span class="go">  name = axi:udmabuf@0x0</span>
<span class="go">  virt addr = 0xffff9469a000</span>
<span class="go">  phys addr = 0x5e100000</span>
<span class="go">  size = 33554432</span>
<span class="go">  flags = 0x2</span>
<span class="go">Transfering 32 bursts</span>
<span class="go">Memory check (size = 32 bursts) successfully completed</span>
<span class="go">Memory check (size = 32 bursts) successfully completed</span>
<span class="go">stats: rd cyc = 140, wr cyc = 248, rd_ok = 128</span>
</code></pre></div>

<p><img alt="AXI Traffic Generator reads - ACP port" src="./images/2021_zynqmp_ports/system_ila/tg_acp.png" style="width:100%; display: block; margin-left: auto; margin-right: auto;"></p>
<h2>FSBL output</h2>
<div class="highlight"><pre><span></span><code><span class="go">Xilinx Zynq MP First Stage Boot Loader </span>
<span class="go">Release 2021.1   Jun  6 2021  -  07:07:32</span>
<span class="go">MultiBootOffset: 0x0</span>
<span class="go">Reset Mode      :       System Reset</span>
<span class="go">Platform: Silicon (4.0), Running on A53-0 (64-bit) Processor, Device Name: XCZU3EG</span>
<span class="go">SD0 Boot Mode </span>
<span class="go">PMU Firmware 2021.1     Jun  6 2021   07:07:32</span>
<span class="go">PMU_ROM Version: xpbr-v8.1.0-0</span>
<span class="go">Protection configuration applied</span>
<span class="go">EL = 3</span>
<span class="go">CCI_REG: register dump</span>
<span class="go">  offset 0 = 0</span>
<span class="go">  offset 10 = 0</span>
<span class="go">  offset 14 = 8000003F</span>
<span class="go">  offset 18 = 0</span>
<span class="go">  offset 1C = 0</span>
<span class="go">  offset 40 = 0</span>
<span class="go">CCI_REG: debug enable</span>
<span class="go">CCI_REG: register dump</span>
<span class="go">  offset 0 = 0</span>
<span class="go">  offset 10 = 0</span>
<span class="go">  offset 14 = 8000003F</span>
<span class="go">  offset 18 = 0</span>
<span class="go">  offset 1C = 0</span>
<span class="go">  offset 40 = 3</span>
<span class="go">CCI: enable snoop, ctrl before = C0000000</span>
<span class="go">CCI: enable snoop, ctrl after = C0000001</span>
<span class="go">CCI: shareable override reg - before = 0</span>
<span class="go">CCI: shareable override reg - after = 3</span>
<span class="go">Exit from FSBL </span>
</code></pre></div>

<hr>
<div style="font-size: 90%;" >
Xilinx, Inc. Xilinx, the Xilinx logo, Vivado, Zynq are trademarks of Xilinx in the United States and
other countries.
</div>

<div style="font-size: 90%;" >
AMBA, ARM, Cortex and TrustZone are registered trademarks of ARM Limited (or its
subsidiaries) in the EU and/or elsewhere. CoreLink is  a trademark of ARM
Limited (or its subsidiaries) in the EU and/or elsewhere.
</div>

<div style="font-size: 90%;" >
All trademarks and registered trademarks are the property of their respective owners.
</div><script src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
        </div><!-- /.entry-content -->
<a href="https://twitter.com/share" class="twitter-share-button" data-count="horizontal" data-via="janmarjanovic">Tweet</a><script type="text/javascript" src="https://platform.twitter.com/widgets.js"></script><br/><br/>

      </article>
    </div>
</section>
        <section id="extras" >
        
        </section><!-- /#extras -->
	
        <footer id="contentinfo" >
                <address id="about" class="vcard ">
                Proudly powered by <a href="https://getpelican.com/" target="_blank">Pelican</a>, which takes
                great advantage of <a href="https://python.org" target="_blank">Python</a>.
		
                </address><!-- /#about -->
		

                
        </footer><!-- /#contentinfo -->

<script data-goatcounter="https://j-marjanovic.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script></body>
</html>